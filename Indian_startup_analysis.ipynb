{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNDING ANALYSIS FOR INDIAN STARTUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[**Step 1: Business Understanding**](#Step-1:-Business-Understanding)\n",
    "\n",
    "[**Step 2: Data Understanding**](#Step-2:-Data-Understanding)\n",
    "\n",
    "- [**Load Data**](#Load-Data)\n",
    "- [**Data Quality**](#Check-Data-Quality)\n",
    "- [**Exploratory Data Analysis-EDA**](#Exploratory-Data-Analysis---EDA)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Business Understanding\n",
    "Team Namibia is trying to venture into the Indian start-up ecosystem. As the data expert of the team, we are to investigate the ecosystem and propose the best course of action.\n",
    "\n",
    "#### Problem Statement:\n",
    "Ideas, creativity, and execution are essential for a start-up to flourish. But are they enough? Investors provide start-ups and other entrepreneurial ventures with the capital---popularly known as \"funding\"---to think big, grow rich, and leave a lasting impact.\n",
    "\n",
    "In this project we are investigating the dynamics of startup funding in India over the period from 2018 to 2021. The aim is to understand the trends, sector preferences, investment stages, key investors, and funding Patterns. Additionally, if there have been significant differences in funding amounts across different years and sectors, it can guide the action plan to be taken.\n",
    "\n",
    "#### Objective\n",
    "In this analysis we will provide insights into the startup funding landscape in India from 2018 to 2021 by: \n",
    "- Identifying trends and patterns in funding amounts over the years.\n",
    "- Determining which sectors received the most funding and how sector preferences changed over time.\n",
    "- Understanding the distribution of funding across different stages of startups (e.g., Seed, Series A).\n",
    "- Identifying key investors and their investment behaviors.\n",
    "- Analyzing the geographical distribution of funding within India.\n",
    "\n",
    "#### Analytical Questions\n",
    "1. What are the trends and patterns in funding amounts for startups in India between 2018 to 2021?\n",
    "   - Analyzing the annual and quarterly trends in funding can reveal patterns and growth trajectories. Look for peaks, dips, and any consistent growth patterns over these years.(Amount, Year funded)\n",
    "2. Which industries received the most funding, and how did industry preferences change over time from 2018 to 2021?\n",
    "   - Identifying which industries or sectors received the most funding can show sectoral preferences and shifts. Understanding how this distribution has evolved over the years can highlight emerging trends and declining interests. (industry, amount, year funded)\n",
    "3. How is the distribution of funding across different stages of startups (e.g., Seed, Series A)?\n",
    "   - Analyzing the funding amounts at different startup stages can provide insights into the investment appetite at various growth phases. It can also help in understanding the maturity and risk preference of investors. (stages, Amount)\n",
    "4. Who are the key investors in Indian startups, and what are their investment behaviors/patterns?\n",
    "   - Identifying the most active investors and analyzing their investment portfolios can shed light on key players in the ecosystem. Understanding their investment patterns can also reveal strategic preferences and alliances.(Investor, amount, industry, stages)\n",
    "5. What is the geographical distribution of startup funding within India, and how has this distribution changed over the years 2018 to 2021?\n",
    "   - Analyzing the geographical distribution of startup funding can show regional hotspots for entrepreneurship and investment. Observing how this has changed over the years can reveal shifts in regional focus and development.(location, year_funded, amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis (H0): There are no significant differences in \n",
    "Amount amongst the group(columns) of factors being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Hypothesis (H1): There are significant differences in \n",
    "Amount amongst the group(columns) of factors being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from 2018 is obtained from GitHub in csv format, 2019 data is obtained from google drive in csv format and 2020 to 2021 data is obtained from an SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install pyodbc and python-dotenv if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyodbc  \n",
    "# %pip install python-dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyodbc library to handle ODBC database connections\n",
    "import pyodbc \n",
    "\n",
    "# Import the dotenv function to load environment variables from a .env file\n",
    "from dotenv import dotenv_values \n",
    "\n",
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Import the warnings library to handle warning messages\n",
    "import warnings\n",
    "\n",
    "# Filter out (ignore) any warnings that are raised\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the numpy library for data manipulation and analysis\n",
    "import numpy as np\n",
    "\n",
    "# Import the seaborn library for data visualization\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing a connection to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the .env file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"UID\")\n",
    "password = environment_variables.get(\"PWD\")\n",
    "\n",
    "# Create the connection string using the retrieved credentials\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2020 & 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53); [08001] [Microsoft][ODBC SQL Server Driver]Invalid connection string attribute (0)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#----------Load 2020 data----------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Establish a connection to the database using the connection string\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpyodbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define the SQL query to select all columns from the specified table\u001b[39;00m\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect * from dbo.LP1_startup_funding2020\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53); [08001] [Microsoft][ODBC SQL Server Driver]Invalid connection string attribute (0)')"
     ]
    }
   ],
   "source": [
    "            #----------Load 2020 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string) \n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2020 = pd.read_sql(query, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           #----------Load 2021 data----------\n",
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "# Define the SQL query to select all columns from the specified table\n",
    "query1 = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "df_2021 = pd.read_sql(query1, connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2018 & 2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2018\n",
    "df_2018 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2018.csv')\n",
    "\n",
    "# Load 2019\n",
    "df_2019 = pd.read_csv(r'C:\\Users\\Pc\\Desktop\\Data analysis\\Azubi Africa\\Career Accelerator\\Indian-Start-up-Funding-Analysis\\Dataset\\startup_funding2019.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2018.columns)\n",
    "print(df_2019.columns)\n",
    "print(df_2020.columns)\n",
    "print(df_2021.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the columns & Save all the data in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 2018 column: 'Round/Series' to 'Funding Stage'\n",
    "df_2018 = df_2018.rename(columns = {'Round/Series': 'Funding Stage'})\n",
    "\n",
    "# Rename 2019 columns\n",
    "df_2019 = df_2019.rename(columns = {'Company/Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'Amount($)': 'Amount', 'HeadQuarter': 'Location', 'What it does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2020 columns\n",
    "df_2020 = df_2020.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n",
    "# Rename 2021 columns\n",
    "df_2021 = df_2021.rename(columns = {'Company_Brand': 'Company Name', 'Sector': 'Industry', 'Stage': 'Funding Stage', 'HeadQuarter': 'Location', 'What_it_does': 'About Company', 'Founded': 'Year Founded'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to each DataFrame to indicate the year\n",
    "df_2018['Year Funded'] = 2018\n",
    "df_2019['Year Funded'] = 2019\n",
    "df_2020['Year Funded'] = 2020\n",
    "df_2021['Year Funded'] = 2021\n",
    "\n",
    "# Concatenate all DataFrames into one master DataFrame\n",
    "df = pd.concat([df_2018, df_2019, df_2020, df_2021], ignore_index=True)\n",
    "\n",
    "\n",
    "# Print out the new DataFrame to confirm the combination was done correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw data\")\n",
    "print(\"2018:\", len(df_2018))\n",
    "print(\"2019:\", len(df_2019))\n",
    "print(\"2020:\", len(df_2020))\n",
    "print(f\"2021: {len(df_2021)}\\n\")\n",
    "\n",
    "print(\"Joined Data\")\n",
    "print(\"2018:\", len(df[df[\"Year Funded\"]== 2018]))\n",
    "print(\"2019:\", len(df[df[\"Year Funded\"]== 2019]))\n",
    "print(\"2020:\", len(df[df[\"Year Funded\"]== 2020]))\n",
    "print(\"2021:\", len(df[df[\"Year Funded\"]== 2021]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns: 'column10', 'Founders' & 'Year Founded' must be removed as they do not help answer our questions.\n",
    "- Review duplicates.\n",
    "- The \"Company Name\" column does not have any may concerns except a few names with \".com\", \".ai\", \".AI\", \".sh\" and \"+\" present.\n",
    "- In the \"Industry\" column:\n",
    "    - \"—\" must be investgated further using the \"About Company\" column in order to fill it with the right data.\n",
    "    - There are companies with multiple industries in a single row, we need to keep only one and remove the rest.\n",
    "    - We can find the unique values in the column and categorize them under specific industries using \"Regular Expression Models\".\n",
    "- There is a link in the \"Funding Stage\" column at index 178.\n",
    "    - There is a link as \"Funding Stage\" \n",
    "    - Investigate \"NaN\" present.\n",
    "    - Investigate \"Undisclosed\"\n",
    "    - Same names are presented differently.\n",
    "- The \"Amount\" column (Prescence of \"₹\", \"$\", \"—\" and \"Undisclosed\"in the column):\n",
    "    - Extract \"₹\" to a new column\n",
    "    - Investigate \"NaN\"\n",
    "    - Replace \"₹\", \"$\" and \"—\" with \"\" in the column\n",
    "    - Investigate \"Undisclosed\"\n",
    "    - Convert the dtype of the column to Int64 as it is in the wrong format.\n",
    "- In the \"Location\" column:\n",
    "    - Investigate \"India, Asia\"\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column, keep the 1st one(containing cities), \n",
    "        - Join it to the main dataframe \"df\"\n",
    "        - Delete the \"Location\"\n",
    "        - Rename the newly joined to \"Location\"\n",
    "- In the \"Investor\" column:\n",
    "    - Investigate \"NaN\"\n",
    "    - Split the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted columns & checking data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "df = df.drop(columns=['column10','Founders','Year Founded'])\n",
    "\n",
    "# checking data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Amount column for further information\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_duplicates= df[df.duplicated(keep = False)].sort_values(by= \"Company Name\")\n",
    "\n",
    "# Check for number of duplicates\n",
    "sum_dups= df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicates:\", sum_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm the new shape. Rows should be less by 23\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows with multiple columns missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with missing data in the \"Amount\" and \"Funding Stage\" columns\n",
    "double_nulls= df[df['Amount'].isna()& df['Funding Stage'].isna()]\n",
    "\n",
    "# Drop them from the database\n",
    "df.drop(double_nulls.index, inplace= True)\n",
    "\n",
    "# Confirm the new shape. Rows should be less by 282\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace \"—\" with nulls\n",
    "- Fill the nulls using the column \"About Company\" as reference\n",
    "- Extract only one Industry from the 'Industry' column\n",
    "- Categorize all Industries into Major Industries (Using regular expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"—\" with Nulls\n",
    "df['Industry'] = df['Industry'].replace('—', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the nulls using the column \"About Company\" as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of company names to industries\n",
    "company_to_industry = {\n",
    "    \"VMate\": \"Media and Entertainment\",\n",
    "    \"Awign Enterprises\": \"Services (Human Resources)\",\n",
    "    \"TapChief\": \"Services (Consulting / Professional Services)\",\n",
    "    \"KredX\": \"Financial Services\",\n",
    "    \"m.Paani\": \"E-Commerce\",\n",
    "    \"Text Mercato\": \"E-Commerce\",\n",
    "    \"Magicpin\": \"E-Commerce\",\n",
    "\t\"Leap Club\": \"E-Commerce\",\n",
    "\t\"Juicy Chemistry\": \"Services\",\n",
    "\t\"Servify\": \"Retail\",\n",
    "\t\"Wagonfly\": \"Media and Entertainment\",\n",
    "\t\"DrinkPrime\": \"E-Commerce\",\n",
    "\t\"Kitchens Centre\": \"Consumer Durables\",\n",
    "\t\"Innoviti\": \"Services\",\n",
    "\t\"Brick&Bolt\": \"Financial Services\",\n",
    "\t\"Toddle\": \"Real Estate\",\n",
    "\t\"HaikuJAM\": \"IT & BPM\",\n",
    "    \"MissMalini Entertainment\" : \"Entertainment and Media\",\n",
    "    \"Jagaran Microfin\" : \"Microfinance\",\n",
    "    \"FLEECA\" : \"Automotive Services\",\n",
    "    \"WheelsEMI\" : \"Financial Services\",\n",
    "    \"Fric Bergen\" : \"Food and Beverage\",\n",
    "    \"Deftouch\" : \"Gaming\",\n",
    "    \"Corefactors\" : \"Marketing\",\n",
    "    \"Cell Propulsion\" : \"Transportation Technology\",\n",
    "    \"Flathalt\" : \"Real Estate\",\n",
    "    \"dishq\" : \"Food Technology\",\n",
    "    \"Trell\" : \"Social Networking\",\n",
    "    \"HousingMan.com\" : \"Real Estate\",\n",
    "    \"Steradian Semiconductors\" : \"Semiconductor Technology\",\n",
    "    \"SaffronStays\" : \"Travel and Hospitality\",\n",
    "    \"Inner Being Wellness\" : \"Beauty and Wellness\",\n",
    "    \"MySEODoc\" : \"Digital Marketing\",\n",
    "    \"ENLYFT DIGITAL SOLUTIONS PRIVATE LIMITED\" : \"Digital Marketing\",\n",
    "    \"Scale Labs\" : \"E-commerce Solutions\",\n",
    "    \"Roadcast\" : \"Business Services\",\n",
    "    \"Toffee\" : \"Insurance Technology\",\n",
    "    \"ORO Wealth\" : \"Financial Services\",\n",
    "    \"Finwego\" : \"Financial Services\",\n",
    "    \"Cred\" : \"Financial Services\",\n",
    "    \"Origo\" : \"Agriculture\",\n",
    "    \"Sequretek\" : \"Cyber Security\",\n",
    "    \"Avenues Payments India Pvt. Ltd.\" : \"IT Solutions\",\n",
    "    \"Planet11 eCommerce Solutions India (Avenue11)\" : \"Technology\",\n",
    "    \"Iba Halal Care\" : \"Cosmetics\",\n",
    "    \"Togedr\" : \"Activity Discovery and Booking\",\n",
    "    \"Scholify\" : \"Edutech\"    \n",
    "}\n",
    "\n",
    "# Function to fill missing industries based on company name\n",
    "def fill_industry(row):\n",
    "    if pd.isna(row[\"Industry\"]):\n",
    "        return company_to_industry.get(row[\"Company Name\"], row[\"Industry\"])\n",
    "    return row[\"Industry\"]\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df[\"Industry\"] = df.apply(fill_industry, axis=1)\n",
    "\n",
    "# Checking the Null value in the 'Industry' column\n",
    "print(\"Null values after cleaning:\",df['Industry'].isna().sum())    # null values changes from 59 to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only one Industry from the 'Industry' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the first industry from the 'Industry' column\n",
    "def industry_extract(row):\n",
    "    industries = row['Industry'].split(',')\n",
    "    return industries[0].strip() if len(industries) > 1 else row['Industry']\n",
    "\n",
    "# Apply the function to update the 'Industry' column\n",
    "df['new_industry'] = df.apply(industry_extract, axis=1)\n",
    "    \n",
    "# Remove \"Industry\"\n",
    "df = df.drop(columns=['Industry'])\n",
    "\n",
    "# Rename \"new_industry\" to \"Industry\"\n",
    "df = df.rename(columns={'new_industry': 'Industry'})\n",
    "\n",
    "df[[\"Industry\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize all Industries into Major Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import re library to work with regular expressions \n",
    "import re\n",
    "\n",
    "# Function to categorize the industries into major ones\n",
    "def sector_redistribution(Industry):\n",
    "    if re.search(r'bank|fintech|finance|mobile payments|crypto|account|credit|venture|crowd|blockchain|microfinance|lending|wealth|insurance|mutual fund|funding|invest|neo-bank|online financial service|escrow|Financial Service', Industry, re.IGNORECASE):\n",
    "        return 'Finance and FinTech'\n",
    "    elif re.search(r'e-?commerce|retail|marketplace|e-store|e-tail|e-tailer|consumer|durables|appliances|electronics', Industry, re.IGNORECASE):\n",
    "        return 'E-Commerce and Retail'\n",
    "    elif re.search(r'marketing|advertising|brand|digital marketing|sales|customer loyalty|creative agency|content management', Industry, re.IGNORECASE):\n",
    "        return 'Marketing and Advertising'\n",
    "    elif re.search(r'agriculture|agtech|agr[iy]tech|food|beverage|catering|cooking|dairy|nutrition|soil', Industry, re.IGNORECASE):\n",
    "        return 'Agriculture and Food'\n",
    "    elif re.search(r'health|medical|biotech|pharma|medtech|care|diagnostics|wellness|fitness|personal care|skincare|mental health|life science|alternative medicine|veterinary', Industry, re.IGNORECASE):\n",
    "        return 'Healthcare and Wellness'\n",
    "    elif re.search(r'transport|automotive|vehicle|logistics|delivery|air transport|mobility|car|bike|EV|auto-tech|transportation', Industry, re.IGNORECASE):\n",
    "        return 'Transportation and Mobility'\n",
    "    elif re.search(r'real estate|construction|interior|housing|home decor|commercial real estate|co-?working|co-?living', Industry, re.IGNORECASE):\n",
    "        return 'Real Estate and Construction'\n",
    "    elif re.search(r'media|entertainment|broadcasting|streaming|video|music|gaming|sports|digital entertainment|visual media', Industry, re.IGNORECASE):\n",
    "        return 'Media and Entertainment'\n",
    "    elif re.search(r'education|e-?learning|edtech|training|continuing education|career planning|edutech', Industry, re.IGNORECASE):\n",
    "        return 'Education'\n",
    "    elif re.search(r'renewable|clean energy|solar|environmental|energy|cleantech|sanitation', Industry, re.IGNORECASE):\n",
    "        return 'Energy and Environment'\n",
    "    elif re.search(r'consulting|business services|professional services|customer service|legal|facility|IT & BPM', Industry, re.IGNORECASE):\n",
    "        return 'Professional Services'\n",
    "    elif re.search(r'information technology|IT|tech|technology|cloud|internet of things|iot|big data|saas|cyber security|software|ai|machine learning|robotics|deep tech|data science|api|digital|platform|networking|smart cities', Industry, re.IGNORECASE):\n",
    "        return 'Technology'\n",
    "    elif re.search(r'consumer goods|consumer applications|consumer durables|consumer electronics|consumer appliances|eyewear|jewellery|fashion', Industry, re.IGNORECASE):\n",
    "        return 'Consumer Goods'\n",
    "    elif re.search(r'industrial|manufacturing|automation|industrial automation|packaging', Industry, re.IGNORECASE):\n",
    "        return 'Industrial and Manufacturing'\n",
    "    else:\n",
    "        return Industry\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Industry'] = df[\"Industry\"].apply(sector_redistribution)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique2= df[\"Industry\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Industries: {len(unique2)}\")       # Unique values changes from 425 to 108\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding another layer of categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sector2_redistribution(Industry):\n",
    "    if re.search(r'technology|computer|embedded systems|AR/VR|aero|aerospace|battery', Industry, re.IGNORECASE):\n",
    "        return 'Technology'\n",
    "    elif re.search(r'fintech|finance|mobile payments|fraud detection|taxation', Industry, re.IGNORECASE):\n",
    "        return 'Finance and FinTech'\n",
    "    elif re.search(r'agriculture|farming|craft beer|dietary supplements|QSR|biomaterial', Industry, re.IGNORECASE):\n",
    "        return 'Agriculture and Food'\n",
    "    elif re.search(r'e-?commerce|retail|marketplace|social commerce|online portals|online games|classifieds|news', Industry, re.IGNORECASE):\n",
    "        return 'E-Commerce and Retail'\n",
    "    elif re.search(r'healthcare|dental|hygiene|wellness|WL & RAC protection', Industry, re.IGNORECASE):\n",
    "        return 'Healthcare and Wellness'\n",
    "    elif re.search(r'media|entertainment|audio|games|reading apps|dating', Industry, re.IGNORECASE):\n",
    "        return 'Media and Entertainment'\n",
    "    elif re.search(r'transportation|mobility|automobile|automobiles', Industry, re.IGNORECASE):\n",
    "        return 'Transportation and Mobility'\n",
    "    elif re.search(r'real estate|construction|rental|warehouse|accommodation|home design', Industry, re.IGNORECASE):\n",
    "        return 'Real Estate and Construction'\n",
    "    elif re.search(r'energy|environment|battery', Industry, re.IGNORECASE):\n",
    "        return 'Energy and Environment'\n",
    "    elif re.search(r'marketing|advertising|market research|content marketplace', Industry, re.IGNORECASE):\n",
    "        return 'Marketing and Advertising'\n",
    "    elif re.search(r'apps|scanning app|reading apps|dating app', Industry, re.IGNORECASE):\n",
    "        return 'Apps'\n",
    "    elif re.search(r'professional services|consultancy|collaboration|service industry', Industry, re.IGNORECASE):\n",
    "        return 'Professional Services'\n",
    "    elif re.search(r'industrial|manufacturing|biomaterial', Industry, re.IGNORECASE):\n",
    "        return 'Industrial and Manufacturing'\n",
    "    elif re.search(r'artificial intelligence|data analytics|data intelligence|analytics|business intelligence', Industry, re.IGNORECASE):\n",
    "        return 'Artificial Intelligence'\n",
    "    elif re.search(r'cosmetics|beauty', Industry, re.IGNORECASE):\n",
    "        return 'Cosmetics'\n",
    "    elif re.search(r'internet|search engine|job portal', Industry, re.IGNORECASE):\n",
    "        return 'Internet'\n",
    "    elif re.search(r'travel|tourism|business travel', Industry, re.IGNORECASE):\n",
    "        return 'Travel'\n",
    "    elif re.search(r'human resources|HR|work fulfillment', Industry, re.IGNORECASE):\n",
    "        return 'Human Resources'\n",
    "    elif re.search(r'education', Industry, re.IGNORECASE):\n",
    "        return 'Education'\n",
    "    else:\n",
    "        return Industry\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Industry'] = df[\"Industry\"].apply(sector2_redistribution)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique3 = df[\"Industry\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Industries: {len(unique3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract \"₹\" to a new column (To help with dollar conversion)\n",
    "- Remove \"₹\", \"$\", \"—\" and \"Undisclosed\" in the column\n",
    "- Change column dtype to \"Int64\" and Convert rupees to dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the symbols into new column (currencies)\n",
    "df['currency'] = df.Amount.str.extract(r'([₹])')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'—' in 'Amount':\", len(df[df['Amount']==\"—\"]))\n",
    "print(\"Null values in 'Amount':\", df['Amount'].isnull().sum())\n",
    "print(\"Number of 'Undisclosed' in 'Amount':\", len(df[df['Amount']==\"Undisclosed\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"₹\", \"$\", \"—\" and \"Undisclosed\" in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"$\", \"₹\", \"—\", \",\" symbols and \"Undisclosed\" from the 'Amount' column\n",
    "df['Amount'] = df['Amount'].replace('[$₹,]', '', regex=True)\n",
    "\n",
    "# Remove empty spaces\n",
    "# df['Amount']=df['Amount'].str.strip()\n",
    "\n",
    "# Replace \"—\" and 'Undisclosed' with Nulls\n",
    "df['Amount'] = df['Amount'].replace(['—','Undisclosed'], np.nan)\n",
    "\n",
    "df[['Amount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'—' in 'Amount':\", len(df[df['Amount']==\"—\"]))\n",
    "print(\"Null values in 'Amount':\", df['Amount'].isnull().sum())\n",
    "print(\"Number of 'Undisclosed' in 'Amount':\", len(df[df['Amount']==\"Undisclosed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Null_vals= df[df['Amount'].isna()].groupby('Year Funded').count()[['Location']]\n",
    "print(\"Null values of years:\", Null_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column dtype to \"float\" and Convert rupees to dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Amount to a numeric column\n",
    "df['Amount'] = pd.to_numeric(df['Amount'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Amount']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered rupees\n",
    "df[df['currency']==\"₹\"][[\"Amount\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #------------Converted all rupees to dollars------------\n",
    "# Give the rate a variable\n",
    "rate = 0.013   # Average rupees to dollars exchange rate from 2018 - 2021\n",
    "\n",
    "# Filter the data for rows that contains \"₹\" in the \"currency\" column\n",
    "rupees = df[df['currency'] == \"₹\"]\n",
    "\n",
    "# Convert all rupees to dollars\n",
    "df.loc[rupees.index, 'Amount']= rupees['Amount']*rate\n",
    "\n",
    "df[df['currency']==\"₹\"][[\"Amount\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Amount\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"currency\" column\n",
    "df = df.drop(columns=['currency'])\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all null values with zeros\n",
    "df['Amount'] = df['Amount'].fillna(0) # This only works in the position\n",
    "\n",
    "df[['Amount']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funding Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change column casing\n",
    "- Remove row with link\n",
    "- Fill nulls with \"Undisclosed\"\n",
    "- Categorize similar Funding stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the case of all rows in the \"Funding Stage\" column to proper case\n",
    "df['Funding Stage'] = df['Funding Stage'].str.title()\n",
    "\n",
    "# Remove the row with the link \n",
    "df= df.drop(df[df['Funding Stage'].str.contains('https:', na=False)].index)\n",
    "\n",
    "# Fill all 974 null values with \"Undisclosed\"\n",
    "df['Funding Stage']= df['Funding Stage'].fillna('Undisclosed')\n",
    "\n",
    "# Print\n",
    "print(\"Null values in Funding Stage:\",df['Funding Stage'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the row with link in the \"Round/Series\"column\n",
    "# df_2018= df_2018.drop(df_2018[df_2018['Funding Stage']=='https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593'].index)\n",
    "df= df.drop(df[df['Funding Stage'].str.contains(\"Https:\")].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize Funding stages to their correct names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to categorize the Funding Stage \n",
    "def stage_correction(Stage):\n",
    "    if re.search(r'Angel|Angel Round', Stage, re.IGNORECASE):\n",
    "        return 'Angel'\n",
    "    elif re.search(r'Bridge|Bridge Round', Stage, re.IGNORECASE):\n",
    "        return 'Bridge'\n",
    "    elif re.search(r'Debt|Debt Financing', Stage, re.IGNORECASE):\n",
    "        return 'Debt Financing'\n",
    "    elif re.search(r'Fresh Funding|Funding Round', Stage, re.IGNORECASE):\n",
    "        return 'Funding Round'\n",
    "    elif re.search(r'Pre Seed Round|Pre-Seed|Pre-Seed Round', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Seed'\n",
    "    elif re.search(r'Pre Series A|Pre- Series A|Pre-Series|Pre-Series A|Pre-Series A1', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series A'\n",
    "    elif re.search(r'Pre Series B|Pre-Series B', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series B'\n",
    "    elif re.search(r'Seed|Seed A|Seed Fund|Seed Funding|Seed Investment|Seed Round', Stage, re.IGNORECASE):\n",
    "        return 'Seed Round'\n",
    "    elif re.search(r'Pre Series C|Pre-Series C', Stage, re.IGNORECASE):\n",
    "        return 'Pre-Series C'\n",
    "    elif re.search(r'Series A|Series A-1', Stage, re.IGNORECASE):\n",
    "        return 'Series A'\n",
    "    elif re.search(r'Series B|Series B+', Stage, re.IGNORECASE):\n",
    "        return 'Series B'\n",
    "    elif re.search(r'Series D|Series D1', Stage, re.IGNORECASE):\n",
    "        return 'Series D'\n",
    "    else:\n",
    "        return Stage\n",
    "    \n",
    "# Apply the function to update the 'Industry' column\n",
    "df['Funding Stage'] = df['Funding Stage'].apply(stage_correction)\n",
    "\n",
    "# Find unique values in the \"Industry\" column\n",
    "unique3= df[\"Funding Stage\"].unique()\n",
    "\n",
    "# Check for number of unique values in the \"Industry\" column\n",
    "print(f\"Number of unique Stages: {len(unique3)}\")         # unique values changes from 50 to 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls with \"Unknown\"\n",
    "df['Investor']= df['Investor'].fillna(\"Unknown\")\n",
    "\n",
    "# Split the column\n",
    "investor_split = df['Investor'].str.rsplit(',', expand=True)\n",
    "\n",
    "# Drop all columns except for \"0\" and \"1\"\n",
    "investor_split= investor_split.drop(investor_split.columns[2:], axis=1)\n",
    "\n",
    "# Assign new column names to the splits\n",
    "investor_split.columns = ['Investor_1', 'Investor_2']\n",
    "\n",
    "# Strip both columns of spaces\n",
    "investor_split[\"Investor_1\"]= investor_split[\"Investor_1\"].str.strip()\n",
    "investor_split[\"Investor_2\"]= investor_split[\"Investor_2\"].str.strip()\n",
    "\n",
    "# Fill the nulls of investor_2 with \"Unknown\"\n",
    "investor_split[\"Investor_2\"]= investor_split[\"Investor_2\"].fillna(\"Unknown\")\n",
    "\n",
    "# Join the investor_split to the existing dataset and delete the Investor column\n",
    "df= df.join(investor_split).drop(\"Investor\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column case\n",
    "df[\"Investor_1\"]= df[\"Investor_1\"].str.lower()\n",
    "df[\"Investor_2\"]= df[\"Investor_2\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract cities from the column & Correct all Typos\n",
    "- Fill nulls based on research at \"pitchbook.com\" and \"crunchbase.com\n",
    "- Filter out Cities that are not located in India\n",
    "- Impute missing values of the unfound Locations of companies with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the first part of the 'Location' column after splitting by a comma. e.g the selection of the city\n",
    "df['Location'] = df['Location'].str.split(pat=',').str[0]\n",
    "\n",
    "# Dictionary of replacements to correct the typos for some locations\n",
    "replacements = {\n",
    "    'Banglore': 'Bengaluru',\n",
    "    'Small Towns': 'Andhra Pradesh',\n",
    "    'Gurugram\\t#REF!': 'Gurugram',\n",
    "    'Samsitpur': 'Bengaluru',\n",
    "    'Telugana': 'Hyderabad',\n",
    "    'Orissia': 'Bengaluru',\n",
    "    'Bangalore City': 'Bengaluru',\n",
    "    'Uttar pradesh': 'Uttar Pradesh'\n",
    "}\n",
    "\n",
    "# Replace typos in the 'Location' column with the correct names\n",
    "df['Location'] = df['Location'].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research was done using \"pitchbook.com\" and \"crunchbase.com\" to discover the location of these startups (with missing values) and inpute their location into the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill nulls based on research at \"pitchbook.com\" and \"crunchbase.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary mapping company names to locations for companies where Location was the only column missing\n",
    "company_to_location = {\n",
    "    'Habitat': 'Chennai',\n",
    "    'Raskik': 'Gurugram',\n",
    "    'Otipy': 'Gurugram',\n",
    "    'Daalchini': 'Noida',\n",
    "    'Bijnis': 'New Delhi',\n",
    "    'Oziva': 'Mumbai',\n",
    "    'Jiffy ai': 'Bengaluru',\n",
    "    'Juicy Chemistry': 'Coimbatore',\n",
    "    'Shiprocket': 'Gurugram',\n",
    "    'Phable': 'Bengaluru',\n",
    "    'NIRA': 'Bengaluru',\n",
    "    'Setu': 'Bengaluru',\n",
    "    'Zupee': 'Gurugram',\n",
    "    'DeHaat': 'Patna',\n",
    "    'CoinDCX': 'Mumbai',\n",
    "    'Smart Coin': 'Bengaluru',\n",
    "    'Shop101': 'Mumbai',\n",
    "    'Neeman': 'Hyderabad',\n",
    "    'SmartVizX': 'Noida',\n",
    "    'Onsitego': 'Mumbai',\n",
    "    'HempStreet': 'Delhi',\n",
    "    'Classplus': 'Noida',\n",
    "    'Fleetx': 'Gurugram',\n",
    "    'Oye! Rickshaw': 'Delhi',\n",
    "    'MoneyTap': 'Bengaluru',\n",
    "    'LogiNext': 'Mumbai',\n",
    "    'Skylo': 'Bengaluru',\n",
    "    'Samya AI': 'Bengaluru',\n",
    "    'Kristal AI': 'Bengaluru',\n",
    "    'Invento Robotics': 'Bengaluru',\n",
    "    'Teach Us': 'Mumbai',\n",
    "    'Phenom People': 'Hyderabad',\n",
    "    'TechnifyBiz': 'Delhi',\n",
    "    'Klub': 'Bengaluru',\n",
    "    'Techbooze': 'Delhi',\n",
    "    'Testbook': 'Gurugram',\n",
    "    'Mamaearth': 'Gurugram',\n",
    "    'EpiFi': 'Bengaluru',\n",
    "    'Vidyakul': 'Gurugram',\n",
    "    'Pristyn Care': 'Gurugram',\n",
    "    'Springboard': 'Bengaluru',\n",
    "    'Bijak': 'Gurugram',\n",
    "    'Rivigo': 'Gurugram',\n",
    "    'Cubical Labs': 'Delhi'\n",
    "}\n",
    "\n",
    "# Function to fill location based on company name\n",
    "def update_location(row):\n",
    "    if row['Company Name'] in company_to_location:\n",
    "        return company_to_location[row['Company Name']]\n",
    "    return row['Location']\n",
    "\n",
    "# Apply the function on the location column\n",
    "df['Location'] = df.apply(update_location, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out Cities that are not located in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of cities that are not located in India\n",
    "non_indian_cities = [\n",
    "    \"Singapore\", \"Frisco\", \"California\", \"New York\", \"San Francisco\", \"San Ramon\",\n",
    "    \"Paris\", \"Plano\", \"Sydney\", \"San Francisco Bay Area\", \"Bangaldesh\", \"London\",\n",
    "    \"Milano\", \"Palmwoods\", \"France\", \"Irvine\", \"Newcastle Upon Tyne\", \"Shanghai\",\n",
    "    \"Jiaxing\", \"San Franciscao\", \"Tangerang\", \"Berlin\", \"Seattle\", \"Riyadh\", \"Seoul\",\n",
    "    \"Bangkok\", \"Hyderebad\", \"Computer Games\", \"Food & Beverages\", \"Pharmaceuticals #REF!\",\n",
    "    \"Beijing\", \"Santra\", \"Mountain View\", \"Online Media #REF!\", \"Information Technology & Services\"\n",
    "]\n",
    "\n",
    "# Filter the dataframe to exclude rows with cities that do not belong\n",
    "df = df[~df['Location'].isin(non_indian_cities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the Location column with Unknown\n",
    "df['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Resetting the DataFrame index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all columns of spaces and converting them to category\n",
    "df['Company Name'] = df['Company Name'].str.strip().astype('category')\n",
    "df['Funding Stage'] = df['Funding Stage'].str.strip().astype('category')\n",
    "df['Location'] = df['Location'].str.strip().astype('category')\n",
    "df['Industry'] = df['Industry'].str.strip().astype('category')\n",
    "df['Investor_1'] = df['Investor_1'].str.strip().astype('category')\n",
    "df['Investor_2'] = df['Investor_2'].str.strip().astype('category')\n",
    "\n",
    "# Replace spaces in column names with \"_\"\n",
    "df.columns = df.columns.str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis: Amount\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define thresholds\n",
    "threshold = 0.05\n",
    "\n",
    "# Perform ANOVA for each factor\n",
    "factors = ['Company_Name','Funding_Stage','Location','Industry','Investor_1','Investor_2']\n",
    "p_values = {}\n",
    "\n",
    "for factor in factors:\n",
    "    model = ols('Amount ~ {}'.format(factor), data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    p_value = anova_table['PR(>F)'][0]\n",
    "    p_value_decimal= round(float(p_value),2)\n",
    "    print(p_value_decimal)\n",
    "\n",
    "    # Add p-value to dictionary\n",
    "    p_values[factor] = p_value_decimal\n",
    "\n",
    "    # # Identify significant factors with p-values below the threshold\n",
    "    significant_factors= [factor for factor, p_values in p_values.items() if p_values < threshold]\n",
    "print(\"Significant factors with p-values below {}: {}\".format(threshold, significant_factors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generating histograms\n",
    "df.hist(\n",
    "    figsize=(15, 15),\n",
    "    layout=(4, 3),\n",
    "    bins=30\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"0\"s in amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of data:\", len(df[\"Amount\"]))\n",
    "print(\"Total number of nulls:\", len(df[df[\"Amount\"]<1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_companies= df[df[\"Amount\"]==0.0]\n",
    "\n",
    "funded_companies_year= funded_companies.groupby(by=\"Year_Funded\")[[\"Amount\"]].count()\n",
    "print(\"Nulls in each yeah:\", funded_companies_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_funds_yearly= df[df[\"Amount\"]>0]\n",
    "print(\"Filled Amount:\", len(avg_funds_yearly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "What are the trends and patterns in funding amounts for startups in India between 2018 to 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group companies that were funded by years\n",
    "years_of_funding= df[df[\"Amount\"]>0].groupby(by=\"Year_Funded\").Amount.count()\n",
    "years_of_funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to convert Series to DataFrame for plotting\n",
    "years_of_funding = years_of_funding.reset_index()\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Year_Funded', y='Amount', data=years_of_funding)\n",
    "plt.xlabel('Number of Companies Funded')\n",
    "plt.ylabel('Year Funded')\n",
    "plt.title('Number of Fundings by Year')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year 2020 & 2021 recieved the most fundings as compaired to the other years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Which Industries received the most funding, and how did industry preferences change over time from 2018 to 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highly funded(sum) and Most funded(count) Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Calculate for Overall sum#----------\n",
    "# Calculate the total sum of fundings for each Industry\n",
    "top_5_industries_sum=  df.groupby(by= \"Industry\")[[\"Amount\"]].sum()\n",
    "top_5_industries_sum_sorted= top_5_industries_sum.sort_values(by= \"Amount\", ascending=False).head(5)\n",
    "\n",
    "print(f\"Top 5 Highly funded Industries:\\n\", top_5_industries_sum_sorted)\n",
    "\n",
    "#----------Calculate for Overall count#----------\n",
    "# Find the top 5 industries that received most funding across the years\n",
    "industry_grouped= df.groupby(by= \"Industry\")[[\"Company_Name\"]]\n",
    "\n",
    "# Calculate the count of the industries\n",
    "top_5_industries_count= industry_grouped.count().sort_values(by= \"Company_Name\", ascending=False).head(5)\n",
    "\n",
    "print(f\"\\nTop 5 most funded Industries:\\n\", top_5_industries_count)\n",
    "\n",
    "\n",
    "print(f\"\\n The 'E-Commerce and Retail' industry got the highest amount of funds, While the Technology industry got the most attention.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating total funding amounts by industry\n",
    "total_funding_by_industry = df.groupby('Industry')['Amount'].sum().reset_index()\n",
    "\n",
    "# Sorting to get the top 5 industries\n",
    "top_5_industries = total_funding_by_industry.sort_values(by='Amount', ascending=False).head(5)['Industry']\n",
    "\n",
    "# Filtering the original DataFrame to include only the top 5 industries\n",
    "top_5_sector_funding = df[df['Industry'].isin(top_5_industries)]\n",
    "\n",
    "# Aggregating funding amounts by year and industry for the top 5 industries\n",
    "sector_funding = top_5_sector_funding.groupby(['Year_Funded', 'Industry'])['Amount'].sum().reset_index()\n",
    "\n",
    "# Plotting sector-wise funding over years for the top 5 industries\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=sector_funding, x='Year_Funded', y='Amount', hue='Industry')\n",
    "plt.title('Sector-wise Funding (Top 5 Industries, 2018-2021)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Funding Amount')\n",
    "plt.legend(title='Industry', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Formatting the y-axis labels\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels(['{:,.0f}'.format(y) for y in ax.get_yticks()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            #-----------------Chart Representation-------------------\n",
    "#------Overall Sum-------\n",
    "# Reset index to convert Series to DataFrame for plotting\n",
    "top_5_industries_sum_sorted_1 = top_5_industries_sum_sorted.reset_index()\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "sns.barplot(x='Industry', y='Amount',data= top_5_industries_sum_sorted_1)\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Total Amount of Funding')\n",
    "plt.title('Top 5 Highly Funded Industries (Sum)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_industries_sum_sorted_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset index to convert Series to DataFrame for plotting\n",
    "top_5_industries_count = top_5_industries_count.reset_index()\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "sns.barplot(x='Industry', y='Company_Name', data=top_5_industries_count)\n",
    "plt.xlabel('Industry')\n",
    "plt.ylabel('Number of Fundings')\n",
    "plt.title('Top 5 most Funded Industries (Count)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #------------Highly Funded industry by year (Sum)------------\n",
    "# Calculate the total sum of fundings for each year\n",
    "yearly_industry_sum= df.groupby(by= [\"Year_Funded\",\"Industry\"])[[\"Amount\"]].sum()\n",
    "\n",
    "# Sort them by \"Amount\" and \"Year_Funded\"\n",
    "yearly_industry_sum_sorted= yearly_industry_sum.sort_values(by= [\"Amount\",\"Year_Funded\"], ascending=False)\n",
    "\n",
    "# Get the first industry with the highest funding amount for each year\n",
    "top_industry_per_year = yearly_industry_sum_sorted.groupby(level=0).head(1)\n",
    "\n",
    "# Sort the list in ascending order\n",
    "sorted_top_industry_per_year= top_industry_per_year.sort_values(by=\"Year_Funded\", ascending=True)\n",
    "\n",
    "\n",
    "    \n",
    "    #------------Most Funded industry by year (Count)------------\n",
    "# Calculate the total sum of fundings for each year\n",
    "yearly_industry_count= df.groupby(by= [\"Year_Funded\",\"Industry\"])[[\"Amount\"]].count()\n",
    "\n",
    "# Sort them by \"Amount\" and \"Year_Funded\"\n",
    "yearly_industry_count_sorted= yearly_industry_count.sort_values(by= [\"Amount\",\"Year_Funded\"], ascending=False)\n",
    "\n",
    "# Get the first industry with the highest funding amount for each year\n",
    "top_industry_per_year_count = yearly_industry_count_sorted.groupby(level=0).head(1)\n",
    "\n",
    "# Sort the list in ascending order\n",
    "top_industry_per_year_count= top_industry_per_year_count.sort_values(by=\"Year_Funded\", ascending=True)\n",
    "\n",
    "\n",
    "# Print out\n",
    "print(\"\\nHighly Funded(Sum) industry by year:\", sorted_top_industry_per_year)\n",
    "print(\"\\n\\nMost Funded(Count) industry by year:\", top_industry_per_year_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Amount', y='Industry', hue='Year_Funded', data=sorted_top_industry_per_year)\n",
    "\n",
    "plt.xlabel('Sum of Funding Amount')\n",
    "plt.ylabel('Industry')\n",
    "plt.title('Higly Funded (Sum) Industries by year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Amount', y='Industry', hue='Year_Funded', data=top_industry_per_year_count)\n",
    "\n",
    "plt.xlabel('Number of Fundings')\n",
    "plt.ylabel('Industry')\n",
    "plt.title('Most Funded (Count) Industries by year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "How is the distribution of funding across different stages of startups (e.g., Seed, Series A)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Calculate for Overall sum for the stages----------\n",
    "# Calculate the total sum of fundings for each Industry\n",
    "top_10_stages_sum=  df[(df[\"Funding_Stage\"] != \"Undisclosed\") & (df[\"Year_Funded\"] == 2020)].groupby(by= \"Funding_Stage\")[[\"Amount\"]].sum()\n",
    "top_10_stages_sum_sorted= top_10_stages_sum.sort_values(by= \"Amount\", ascending=False).head()\n",
    "\n",
    "#----------Calculate for Overall Count for the stages----------\n",
    "# Calculate the total sum of fundings for each Industry\n",
    "top_10_stages_count=  df[df[\"Funding_Stage\"]!=\"Undisclosed\"].groupby(by= \"Funding_Stage\")[[\"Amount\"]].count()\n",
    "top_10_stages_sorted_count= top_10_stages_count.sort_values(by= \"Amount\", ascending=False).head()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Top 5 overall most funded stages(count):\", top_10_stages_sorted_count,\"\\n\")\n",
    "print(f\"Top 5 stages with the highest amount of fundings:\", top_10_stages_sum_sorted)\n",
    "\n",
    "# There are 30 funding stages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "A- Who are the key investors in Indian startups?\n",
    "\n",
    "B- What are their investment behaviors/patterns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Replace 'Sequoia Capital India' with 'Sequoia Capital' in both 'Investor1' and 'Investor2' columns\n",
    "# df['Investor_1'] = df['Investor_1'].replace('Sequoia Capital India', 'Sequoia Capital')\n",
    "# df['Investor_2'] = df['Investor_2'].replace('Sequoia Capital India', 'Sequoia Capital')\n",
    "\n",
    "# # Filtering out rows with 'unknown' or 'undisclosed' in both 'Investor1' and 'Investor2' columns\n",
    "# df_filtered = df[~df['Investor_1'].isin(['unknown', 'undisclosed', 'Unknown', 'Undisclosed'])]\n",
    "# df_filtered = df_filtered[~df_filtered['Investor_2'].isin(['unknown', 'undisclosed', 'Unknown', 'Undisclosed'])]\n",
    "\n",
    "# # Combine both investor columns into a single Series\n",
    "# investors_combined = pd.concat([df_filtered['Investor_1'], df_filtered_1['Investor_2']])\n",
    "\n",
    "# # Create a DataFrame from the combined investors list\n",
    "# investors_summary = investors_combined.value_counts().reset_index()\n",
    "# investors_summary.columns = ['Investor', 'Startup Count']\n",
    "\n",
    "# # Select the top 10 investors\n",
    "# investors_summary = investors_summary.head(10)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# ax = sns.barplot(data=investors_summary, x='Startup Count', y='Investor', orient='h')\n",
    "# plt.title('Investors Who Funded Most Start-Ups', fontsize=20, weight='bold')\n",
    "# plt.xlabel('Startup Count')\n",
    "# plt.ylabel('Investor')\n",
    "\n",
    "# # Adding data labels\n",
    "# for index, value in enumerate(investors_summary['Startup Count']):\n",
    "#     ax.text(value, index, f'{value}', va='center', ha='left', color='black', fontweight='bold')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"undisclosed\" with \"unknown\"\n",
    "df[\"Investor_1\"]= df[\"Investor_1\"].str.replace(\"undisclosed\",\"unknown\")\n",
    "df[\"Investor_2\"]= df[\"Investor_2\"].str.replace(\"undisclosed\",\"unknown\")\n",
    "df_needed= df[['Amount', 'Investor_1', 'Investor_2']]\n",
    "\n",
    "# Filter out \"unknown\" values from Investor_1\n",
    "df_needed1= df_needed.drop(df_needed[df_needed[\"Investor_1\"]==\"unknown\"].index)\n",
    "\n",
    "# Top 5 counts of investors from Investor_1\n",
    "df_top_5_investors_1 = df_needed1.value_counts(\"Investor_1\").head()\n",
    "\n",
    "# Top 5 counts of investors from Investor_2\n",
    "df_top_5_investors_2= df_needed1.value_counts(\"Investor_2\").head().iloc[1::]\n",
    "\n",
    "print(\"Top 5 Active of investors from Investor_1\\n\",df_top_5_investors_1)\n",
    "print(\"\\n\\nTop 5 Active of investors from Investor_2\\n\",df_top_5_investors_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can derive that, \"sequoia capital india\" is the most active investor as they have invested in more companies than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Big Investors whith their partners\n",
    "Investor_sum= df_needed1.groupby(\"Investor_1\").sum().sort_values(by= \"Amount\", ascending=False).head(5)\n",
    "\n",
    "print(\"Top 5 Big Investors\\n\",Investor_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Big player in the start-up investment ecosystem is:\n",
    "\"Silver lake\" who mostly partners with \"Mubadala Investment Company\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "A- What is the geographical distribution of startup funding within India?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a histogram to visualize the number of startups in each Location\n",
    "startup_count_per_hq = df.groupby('Location').size().reset_index(name='Startup Count')\n",
    "\n",
    "# Sort the DataFrame by 'Startup Count' in descending order\n",
    "startup_count_per_hq_sorted = startup_count_per_hq.sort_values(by='Startup Count', ascending=False)\n",
    "startup_count_per_hq_sorted=startup_count_per_hq_sorted.head(10)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(startup_count_per_hq_sorted['Location'],startup_count_per_hq_sorted['Startup Count'])\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Start-ups', fontsize=18)\n",
    "plt.ylabel('City', fontsize=18)\n",
    "plt.title('Top Ten Locations with the Most Start-ups Funded', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.\n",
    "\n",
    "B- How has this distribution changed over the years 2018 to 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregating data by 'City' and 'Year'\n",
    "funding_by_city_year = df.groupby(['Location', 'Year_Funded'])['Amount'].sum().unstack().fillna(0)\n",
    "\n",
    "\n",
    "# Calculating total funding for each city across all years\n",
    "total_funding_by_city = funding_by_city_year.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# Getting the top 10 cities by total funding\n",
    "top_10_cities = total_funding_by_city.head(10).index\n",
    "\n",
    "# Filtering the original aggregated data to include only the top 10 cities\n",
    "top_10_funding_by_city_year = funding_by_city_year.loc[top_10_cities]\n",
    "\n",
    "# Plotting the changes over the years for the top 10 cities\n",
    "top_10_funding_by_city_year.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "plt.title('Changes in Geographical Distribution of Startup Funding (2018-2021) for Top 10 Cities')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Total Funding Amount')\n",
    "plt.legend(title='Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this period, it was observed that the 3 cities with the most funding for startups were Bangalore, Mumbai and Gurugram respectively yet trend of ivnestment capital being poured into these regions doesnt follow the same order. With respect to the invesmtnets being credited to startups over the past 4 years, Mumbai rather has seen the largest influx followed by Bangalore with Gurugram not making top 5. This could suggest that over the years, there has been a decline in the investment capital awarded to startups in that city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #------------Highly Funded industries by year (Sum)------------\n",
    "\n",
    "# Calculate the total sum of fundings for each year\n",
    "yearly_stage_sum= df[df[\"Funding_Stage\"]!=\"Undisclosed\"].groupby(by= [\"Year_Funded\",\"Funding_Stage\"])[[\"Amount\"]].sum()\n",
    "\n",
    "# Sort them by \"Amount\" and \"Year_Funded\"\n",
    "yearly_stage_sum_sorted= yearly_stage_sum.sort_values(by= [\"Amount\",\"Year_Funded\"], ascending=False)\n",
    "\n",
    "# Get the first industry with the highest funding amount for each year\n",
    "yearly_stage_sum_sorted = yearly_stage_sum_sorted.groupby(level=0).head(1)\n",
    "\n",
    "# Sort the list in ascending order\n",
    "yearly_stage_sum_sorted= yearly_stage_sum_sorted.sort_values(by=\"Year_Funded\", ascending=True)\n",
    "\n",
    "\n",
    "            #------------Most Funded industry by year (Count)------------\n",
    "\n",
    "# Calculate the total sum of fundings for each year\n",
    "yearly_stage_count= df[df[\"Funding_Stage\"]!=\"Undisclosed\"].groupby(by= [\"Year_Funded\",\"Funding_Stage\"])[[\"Amount\"]].count()\n",
    "\n",
    "# Sort them by \"Amount\" and \"Year_Funded\"\n",
    "yearly_stage_count_sorted= yearly_stage_count.sort_values(by= [\"Amount\",\"Year_Funded\"], ascending=False)\n",
    "\n",
    "# Get the first industry with the highest funding amount for each year\n",
    "top_stage_per_year_count = yearly_stage_count_sorted.groupby(level=0).head(1)\n",
    "\n",
    "# Sort the list in ascending order\n",
    "top_stage_per_year_count= top_stage_per_year_count.sort_values(by=\"Year_Funded\", ascending=True)\n",
    "\n",
    "top_stage_per_year_count\n",
    "\n",
    "# Print Results\n",
    "print(\"\\nHighly Funded(Sum) stage by year:\", yearly_stage_sum_sorted)\n",
    "print(\"\\n\\nMost Funded(Count) stage by year:\", top_stage_per_year_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Industry\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_combined_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
